# 혼성모델/앙상블

에러는 두가지로 구성된다 variance + bias. 오버피팅되면 variance가 발생하고, 언더피팅되면 bias가 발생한다. 데이터가 많다면 동시 해결이 가능하지만 제한적 데이터에서는 앙상블이 해결책이다. 
- variance해결 : 배깅(eg. Random Forest)
- bias해결 : 부스팅(eg. adboosting, xgBoosting)
- variance + bias 해결 : 스태킹  

![](http://i.imgur.com/w2Ngw2u.png)

혼성 모델 
- 앙상블 : 같은 문제에 서로 다른 알고리즘 적용 하여 문제 해결 
- 연산공유 : 하나의 해에 2개 이상의 알고리즘이 개입 (eg. 유전알고리즘 + 순차 탐색, 신경망 + 퍼지)

혼성 모델을 사용하는 몇 가지 이유
- 나쁜 운을 피할 수 있다.
- 성능 향상을 꾀할 수 있다.
- 데이터 양에 따른 어려움을 극복할 수 있다.
- 데이터 질에 따른 어려움을 극복할 수 있다.
- 다중 센서 시스템에서 효과적이다.
- 결정 경계가 너무 복잡한 경우에 효과적일 수 있다.
- 점진 학습이 가능하다.



![](http://i.imgur.com/wSZt4LW.png)



## 1. 앙상블 생성 

앙상블(다중 분류기) 생성 
- 방법 1 : 훈련집합을 재 샘플링 (eg. 배깅, 부스팅) 
- 방법 2 : 서로 다른 분류 알고리즘을 사용하는 방식 

|다양성을 가지는 분류기 생성이 초점|
|-|

> 메타 휴리스틱 : 다른 알고리즘을 포함하고 있는 알고리즘 

### 1.1 배깅

### 1.2 부스팅 

## 2. 앙상블 결합

목적: 다중 분류기의 출력을 결합하여 하나의 분류 결과를 만드는 과정 

고려 사항 : 요소 분류기의 출력 특성을 고려 하여야 함 

- Class label(부류 표지) : 1 or 0 

- Class ranking(부류 순위) : 1 ~ M 까지의 정수 

- Class probability(부류 확률) : 부류에 속할 확률 (eg. 베이시언 분류기)

Class  probability $$\rightarrow$$ Class label/ranking로 변환 가능 (단, 반대는 불가)

> 신경망, SVM은 부류별 실수값 출력(확률아님), Softmax()로 변환하여 확률로 간주 가능 

### 2.1 Class label(부류 표지)

#### A. 다수 투표 (Majority voting)
최다 투표자를 선출 하는 방식과 유사 

$$
q = argmax_{j=1,M}\sum^T_{t=1} l_{tj}
$$
- 미지의 패턴 x를 T개의 분류기로 분류 하여 $$L_1, L_2, ..., L_T $$를 구하고 q를 결정하여 최종적으로 x를 $$\omega_q$$ 로 분류  


#### B. 가중 다수 투표 (Weighted Majority voting)

- 명성이 있는(신뢰도가 높은) 분류기에 큰 비중을 두는 방식 
$$
q = argmax_{j=1,M}\sum^T_{t=1} \alpha_tl_{tj}
$$

#### C. 행위 지식 공간 (BKS: Behavior Knowledge space)
기존 방식은 유권자가 후보자 각각에 대해 알고 있는 지식을 고려 하지 않았다. 

BKS = 사전지식을 고려 하는 방식 (eg. 후보자 2는 특정 Task_a에 대하여 정확도가 크다)

### 2.2 Class Ranking(부류 순위) 
유권자가 가장 좋아 하는 한명의 후보에게 투표하는 것이 아니라, M명의 후보를 선호도에 따라 순위(Rank)를 매기는 것과 유사 

#### A. Borda 계수 
1770년 Hean Charles de Borda가 제안. (eg. 국회의원선출(슬로베이아), 야구 MVP선출(한국)

$$
q = argmax_{j=1,M}\sum^T_{t=1}S_{tj}
$$

### 2.3 Class Probability(부류 확률)
확률은 0~1 사이의 실수 이므로 아래와 같은 연산이 가능하다. 

![](http://i.imgur.com/fKucNTe.png)

위 연산중의 하나로 $$\beta$$를 구하고 벡터 형태 B에서 가장 큰값을 같는 부류 $$\omega_q$$를 선택 하면 된다. 
    - 일반적으로 합/가중합 규칙을 많이 사용 

$$
q = argmax_{j=1,M}\beta_j

$$

## 3. 앙상블 선택 
Option적 요소(반드시 수행할 필요 없음)

### 3.1 척도 

선택을 위하여 다양한 척도들이 존재 한다. 

[[Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy]](https://link.springer.com/article/10.1023%2FA%3A1022859003006?LI=true)에서 정리한 10개의 척도 중 7개를 중심적으로 살펴봄 

#### A. 분류기 쌍간의 값을 활용 하여 다양성 판단

![](http://i.imgur.com/XituHy9.png)
T개 분류기 간의 다양성 (평균이용)
- 모두 [0,1]사이의 값을 가짐
- 불일치를 빼고 값이 클수록 다양성 떨어짐 (불일치는 반대)


##### 가. Q-통계

- 1900년 Yule제안한 척도 
- [-1, 1]사이의 값을 가짐 
    - 양수 : 두 분류기가 맞추는 경향이 어느정도 일지 
    - 음수 : 두 분류기가 틀리는 샘플이 많으면 
    
![](http://i.imgur.com/3TyQt3p.png)


##### 나. 상관계수
- Q-통계와 같은 특성 가짐 

![](http://i.imgur.com/zl3Z4cA.png)
$$q_ik=0$$일때 다양성이 최대가 된다. 

##### 다. 불일치
- 두 분류기의 의견이 같은 경우는 무시하고 다른 경우만 사용한다. 
- 불일치 척도는 [0,1] 사이의 값을 가짐 
 - 0 : 두 분류기가 모든 샘플에 대해 의견이 일치 
 - 1 : 두 분류기가 모든 샘플에 대해 의견이 불일치 

![](http://i.imgur.com/FwJ9uKE.png)
$$d_ik=1$$일때 다양성이 최대가 된다. 

##### 라. 이중과실 
- 두 분류기가 모두 과실을 범하는 경우만 사용 
- [0,1] 사이의 값을 가짐 
    - 0 : 다양성이 크다
    - 1 : 다양성이 낮다
    
![](http://i.imgur.com/S32LXIy.png)
$$f_ik=1$$ 일때 다양성이 최소가 된다. 


#### B. 바로 분류기의 값으로 다양성 판단

##### 가. 엔트로피 
- 기본 아이디어
    - 샘플을 맞추는 분류기와 틀리는 분류기가 5:5 라면 -> 다양성이 크다. 
    - 모두 맞추거나, 모두 틀린다면 -> 다양성이 작다 

- [0,1] 사이의 값을 가짐 
    - 0 : 분류기들이 모두 같다
    - 1 : 다양성이 크다. 
    
![](http://i.imgur.com/prHeBp7.png)


##### 나. Kohavi-Wolpert 분산 
- [0, $$\frac{1}{4}$$]사이의 값을 가짐 
    - 0 : 분류기들이 모두 같음 
    - $$\frac{1}{4}$$ : 다양성이 가장 큰 경우 

![](http://i.imgur.com/NLYX4FQ.png)

##### 다. 평가자 동의(Interrater agreement)
- p는 분류기들의 평균 정인식률
- 값이 클수록 다양성이 떨어 진다. 

![](http://i.imgur.com/8vES6VK.png)

### 3.2 선택 알고리즘 
![](http://i.imgur.com/MwHxuXZ.png)

앙상블 선택 문제에 적용 가능한 알고리즘 
- 임의 탐색 알고리즘 
- 개별 특징 평가 알고리즘 
- 낱낱 탐색 알고리즘 
- 한정 분기 알고리즘
- 순차 탐색 알고리즘
- 유전 알고리즘  


---

- [Bagging, Boosting and Stacking](http://hugrypiggykim.com/2019/04/07/bagging-boosting-and-stacking/)
